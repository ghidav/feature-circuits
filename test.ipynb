{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=Sat Aug 03 13:31:54 2024\n",
      "╒═════════════════════════════════════════════════════════════════════════════╕\n",
      "│ NVITOP 1.3.2      Driver Version: 535.129.03      CUDA Driver Version: 12.2 │\n",
      "├───────────────────────────────┬──────────────────────┬──────────────────────┤\n",
      "│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ MIG M.   Uncorr. ECC │\n",
      "│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │\n",
      "╞═══════════════════════════════╪══════════════════════╪══════════════════════╡\n",
      "│\u001b[31m   0  A100 80GB PCIe      On   \u001b[0m│\u001b[31m 00000000:81:00.0 Off \u001b[0m│\u001b[31m Disabled           0 \u001b[0m│\n",
      "│\u001b[31m N/A   51C    P0   202W / 300W \u001b[0m│\u001b[31m  76.29GiB / 80.00GiB \u001b[0m│\u001b[31m     68%      Default \u001b[0m│\n",
      "╘═══════════════════════════════╧══════════════════════╧══════════════════════╛\n",
      "\u001b[1m\u001b[36m[ CPU: ▍ 1.4%          UPTIME: 198.5 days ]\u001b[0m  \u001b[1m( Load Average:  1.22  1.19  1.29 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: █▍ 4.6%              USED: 9.37GiB ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: █▎ 5.9%                    ]\u001b[0m\n",
      "\n",
      "╒══════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Processes:                                                 \u001b[1m\u001b[33mroot\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32m4e225b6ab175\u001b[0m │\n",
      "│ GPU     PID      USER  GPU-MEM %SM  %CPU  %MEM  TIME  COMMAND                │\n",
      "╞══════════════════════════════════════════════════════════════════════════════╡\n",
      "│\u001b[31m   0\u001b[0m 2429059 C     N/A 76.28GiB  61   N/A   N/A   N/A  \u001b[31mNo Such Process\u001b[0m        │\n",
      "╘══════════════════════════════════════════════════════════════════════════════╛\n",
      "\u001b[1m\u001b[31mERROR:\u001b[0m Failed to initialize `curses` (curs_set() returned ERR)\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          88G   45G   44G  51% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              62G  4.0K   62G   1% /dev/shm\n",
      "/dev/nvme0n1p3  3.5T  933G  2.6T  27% /etc/hosts\n",
      "/dev/nvme0n1p2   32G   21G   12G  66% /usr/bin/nvidia-smi\n",
      "tmpfs           126G   12K  126G   1% /proc/driver/nvidia\n",
      "tmpfs           126G  4.0K  126G   1% /etc/nvidia/nvidia-application-profiles-rc.d\n",
      "tmpfs            26G   31M   26G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           126G     0  126G   0% /proc/acpi\n",
      "tmpfs           126G     0  126G   0% /proc/scsi\n",
      "tmpfs           126G     0  126G   0% /sys/firmware\n",
      "tmpfs           126G     0  126G   0% /sys/devices/virtual/powercap\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tens = torch.load('circuits/simple_train_dict10_node0.1_edge0.01_n128_aggsum.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'examples': [{'clean_prefix': tensor([[    2,   651, 10194]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5780]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4034]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4078]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 6494]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 7705]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4323]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 3576]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5780]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10194]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'patch_prefix': tensor([[  2, 651, 916]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[  2, 651, 916]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5842]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 39935]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 193419]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 88634]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 193419]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 88634]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 21255]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 32047]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 3576]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4323]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'patch_prefix': tensor([[  2, 651, 916]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5290]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 28219]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 3576]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4323]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4034]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4078]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 6494]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 7705]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 8216]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4602]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4602]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 8216]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 6494]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 7705]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 138851]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 32011]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'patch_prefix': tensor([[  2, 651, 916]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 26354]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 16252]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 26354]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 16252]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5780]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10194]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4034]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4078]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4078]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4034]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 10194]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5780]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32011]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 138851]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[  2, 651, 916]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 44418]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 32566]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 193419]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 88634]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[  2, 651, 916]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 26354]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 16252]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 46551]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 12600]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32566]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 44418]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32047]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21255]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32047]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21255]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 16252]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 26354]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 28219]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5290]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5780]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10194]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 88634]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 193419]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 193419]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 88634]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 193419]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 88634]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4602]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 8216]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 46551]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 12600]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 10194]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5780]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32011]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 138851]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 138851]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 32011]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'patch_prefix': tensor([[  2, 651, 916]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4602]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 8216]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 44418]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 32566]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 8216]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4602]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 12600]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 46551]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 44418]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 32566]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5842]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 39935]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4034]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4078]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32011]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 138851]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 46551]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 12600]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[     2,    651, 138851]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 32011]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20671]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9353]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 6494]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 7705]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 47189]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 153684]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 16252]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 26354]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 88634]]),\n",
       "   'patch_prefix': tensor([[     2,    651, 193419]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32047]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21255]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 12600]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 46551]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 46551]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 12600]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4078]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 4034]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[  2, 651, 916]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 1359]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5982]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 8586]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32047]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21255]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4323]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 3576]]),\n",
       "   'clean_answer': 1721,\n",
       "   'patch_answer': 749,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 28219]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5290]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 68106]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21826]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 10522]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 9382]]),\n",
       "   'clean_answer': 749,\n",
       "   'patch_answer': 1721,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 4323]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 3576]]),\n",
       "   'clean_answer': 919,\n",
       "   'patch_answer': 791,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 7705]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 6494]]),\n",
       "   'clean_answer': 6128,\n",
       "   'patch_answer': 871,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 28219]]),\n",
       "   'patch_prefix': tensor([[   2,  651, 5290]]),\n",
       "   'clean_answer': 871,\n",
       "   'patch_answer': 6128,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 20516]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 17015]]),\n",
       "   'clean_answer': 708,\n",
       "   'patch_answer': 603,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[    2,   651, 32047]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 21255]]),\n",
       "   'clean_answer': 791,\n",
       "   'patch_answer': 919,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3},\n",
       "  {'clean_prefix': tensor([[   2,  651, 5842]]),\n",
       "   'patch_prefix': tensor([[    2,   651, 39935]]),\n",
       "   'clean_answer': 603,\n",
       "   'patch_answer': 708,\n",
       "   'annotations': {'the_subj': (0, 1), 'subj_main': (2, 3)},\n",
       "   'prefix_length_wo_pad': 3}],\n",
       " 'nodes': {'embed': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       "  'attn_0': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_0': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_0': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_1': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_1': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_1': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_2': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_2': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_2': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_3': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_3': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_3': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_4': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_4': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_4': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_5': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_5': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_5': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_6': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_6': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_6': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_7': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_7': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_7': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_8': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_8': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_8': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_9': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_9': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_9': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_10': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_10': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_10': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_11': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_11': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_11': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_12': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_12': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_12': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_13': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_13': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_13': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_14': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_14': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_14': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_15': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_15': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_15': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_16': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_16': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_16': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_17': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_17': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_17': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_18': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_18': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_18': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_19': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_19': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_19': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_20': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_20': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_20': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_21': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_21': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_21': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_22': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_22': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_22': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_23': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_23': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_23': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_24': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_24': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_24': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'attn_25': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'mlp_25': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'resid_25': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')},\n",
       " 'edges': {'resid_25': {'y': tensor(indices=tensor([], size=(1, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385,), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_25': {'resid_25': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_25': {'resid_25': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_24': {'mlp_25': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_25': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_25': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_24': {'resid_24': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_24': {'resid_24': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_23': {'mlp_24': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_24': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_24': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_23': {'resid_23': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_23': {'resid_23': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_22': {'mlp_23': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_23': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_23': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_22': {'resid_22': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_22': {'resid_22': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_21': {'mlp_22': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_22': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_22': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_21': {'resid_21': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_21': {'resid_21': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_20': {'mlp_21': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_21': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_21': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_20': {'resid_20': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_20': {'resid_20': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_19': {'mlp_20': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_20': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_20': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_19': {'resid_19': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_19': {'resid_19': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_18': {'mlp_19': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_19': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_19': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_18': {'resid_18': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_18': {'resid_18': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_17': {'mlp_18': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_18': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_18': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_17': {'resid_17': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_17': {'resid_17': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_16': {'mlp_17': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_17': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_17': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_16': {'resid_16': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_16': {'resid_16': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_15': {'mlp_16': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_16': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_16': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_15': {'resid_15': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_15': {'resid_15': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_14': {'mlp_15': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_15': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_15': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_14': {'resid_14': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_14': {'resid_14': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_13': {'mlp_14': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_14': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_14': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_13': {'resid_13': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_13': {'resid_13': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_12': {'mlp_13': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_13': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_13': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_12': {'resid_12': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_12': {'resid_12': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_11': {'mlp_12': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_12': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_12': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_11': {'resid_11': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_11': {'resid_11': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_10': {'mlp_11': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_11': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_11': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_10': {'resid_10': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_10': {'resid_10': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_9': {'mlp_10': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_10': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_10': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_9': {'resid_9': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_9': {'resid_9': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_8': {'mlp_9': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_9': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_9': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_8': {'resid_8': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_8': {'resid_8': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_7': {'mlp_8': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_8': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_8': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_7': {'resid_7': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_7': {'resid_7': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_6': {'mlp_7': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_7': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_7': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_6': {'resid_6': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_6': {'resid_6': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_5': {'mlp_6': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_6': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_6': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_5': {'resid_5': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_5': {'resid_5': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_4': {'mlp_5': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_5': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_5': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_4': {'resid_4': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_4': {'resid_4': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_3': {'mlp_4': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_4': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_4': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_3': {'resid_3': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_3': {'resid_3': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_2': {'mlp_3': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_3': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_3': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_2': {'resid_2': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_2': {'resid_2': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_1': {'mlp_2': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_2': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_2': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_1': {'resid_1': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_1': {'resid_1': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'resid_0': {'mlp_1': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_1': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_1': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'mlp_0': {'resid_0': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'attn_0': {'resid_0': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 16385), nnz=0, layout=torch.sparse_coo)},\n",
       "  'embed': {'mlp_0': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 2305), nnz=0, layout=torch.sparse_coo),\n",
       "   'attn_0': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 2305), nnz=0, layout=torch.sparse_coo),\n",
       "   'resid_0': tensor(indices=tensor([], size=(2, 0)),\n",
       "          values=tensor([], size=(0,)),\n",
       "          device='cuda:0', size=(16385, 2305), nnz=0, layout=torch.sparse_coo)}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import json\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = keys['huggingface']\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.66it/s]\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_HOME\"] = \"/workspace/huggingface\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-2b\", device='cuda')\n",
    "model.tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokens = model.to_tokens(\"I am a cat\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logit, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActivationCache with keys ['hook_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.ln1_post.hook_scale', 'blocks.0.ln1_post.hook_normalized', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_pre_linear', 'blocks.0.mlp.hook_post', 'blocks.0.ln2_post.hook_scale', 'blocks.0.ln2_post.hook_normalized', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_rot_q', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.ln1_post.hook_scale', 'blocks.1.ln1_post.hook_normalized', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_pre_linear', 'blocks.1.mlp.hook_post', 'blocks.1.ln2_post.hook_scale', 'blocks.1.ln2_post.hook_normalized', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_rot_q', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.ln1_post.hook_scale', 'blocks.2.ln1_post.hook_normalized', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_pre_linear', 'blocks.2.mlp.hook_post', 'blocks.2.ln2_post.hook_scale', 'blocks.2.ln2_post.hook_normalized', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_rot_q', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.ln1_post.hook_scale', 'blocks.3.ln1_post.hook_normalized', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_pre_linear', 'blocks.3.mlp.hook_post', 'blocks.3.ln2_post.hook_scale', 'blocks.3.ln2_post.hook_normalized', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_rot_q', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.ln1_post.hook_scale', 'blocks.4.ln1_post.hook_normalized', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_pre_linear', 'blocks.4.mlp.hook_post', 'blocks.4.ln2_post.hook_scale', 'blocks.4.ln2_post.hook_normalized', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_rot_q', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.ln1_post.hook_scale', 'blocks.5.ln1_post.hook_normalized', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_pre_linear', 'blocks.5.mlp.hook_post', 'blocks.5.ln2_post.hook_scale', 'blocks.5.ln2_post.hook_normalized', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_rot_q', 'blocks.6.attn.hook_rot_k', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.ln1_post.hook_scale', 'blocks.6.ln1_post.hook_normalized', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_pre_linear', 'blocks.6.mlp.hook_post', 'blocks.6.ln2_post.hook_scale', 'blocks.6.ln2_post.hook_normalized', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_rot_q', 'blocks.7.attn.hook_rot_k', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.ln1_post.hook_scale', 'blocks.7.ln1_post.hook_normalized', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_pre_linear', 'blocks.7.mlp.hook_post', 'blocks.7.ln2_post.hook_scale', 'blocks.7.ln2_post.hook_normalized', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_rot_q', 'blocks.8.attn.hook_rot_k', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.ln1_post.hook_scale', 'blocks.8.ln1_post.hook_normalized', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_pre_linear', 'blocks.8.mlp.hook_post', 'blocks.8.ln2_post.hook_scale', 'blocks.8.ln2_post.hook_normalized', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_rot_q', 'blocks.9.attn.hook_rot_k', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.ln1_post.hook_scale', 'blocks.9.ln1_post.hook_normalized', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_pre_linear', 'blocks.9.mlp.hook_post', 'blocks.9.ln2_post.hook_scale', 'blocks.9.ln2_post.hook_normalized', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_rot_q', 'blocks.10.attn.hook_rot_k', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.ln1_post.hook_scale', 'blocks.10.ln1_post.hook_normalized', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_pre_linear', 'blocks.10.mlp.hook_post', 'blocks.10.ln2_post.hook_scale', 'blocks.10.ln2_post.hook_normalized', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_rot_q', 'blocks.11.attn.hook_rot_k', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.ln1_post.hook_scale', 'blocks.11.ln1_post.hook_normalized', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_pre_linear', 'blocks.11.mlp.hook_post', 'blocks.11.ln2_post.hook_scale', 'blocks.11.ln2_post.hook_normalized', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'blocks.12.hook_resid_pre', 'blocks.12.ln1.hook_scale', 'blocks.12.ln1.hook_normalized', 'blocks.12.attn.hook_q', 'blocks.12.attn.hook_k', 'blocks.12.attn.hook_v', 'blocks.12.attn.hook_rot_q', 'blocks.12.attn.hook_rot_k', 'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', 'blocks.12.attn.hook_z', 'blocks.12.ln1_post.hook_scale', 'blocks.12.ln1_post.hook_normalized', 'blocks.12.hook_attn_out', 'blocks.12.hook_resid_mid', 'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_pre_linear', 'blocks.12.mlp.hook_post', 'blocks.12.ln2_post.hook_scale', 'blocks.12.ln2_post.hook_normalized', 'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_post', 'blocks.13.hook_resid_pre', 'blocks.13.ln1.hook_scale', 'blocks.13.ln1.hook_normalized', 'blocks.13.attn.hook_q', 'blocks.13.attn.hook_k', 'blocks.13.attn.hook_v', 'blocks.13.attn.hook_rot_q', 'blocks.13.attn.hook_rot_k', 'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', 'blocks.13.attn.hook_z', 'blocks.13.ln1_post.hook_scale', 'blocks.13.ln1_post.hook_normalized', 'blocks.13.hook_attn_out', 'blocks.13.hook_resid_mid', 'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_pre_linear', 'blocks.13.mlp.hook_post', 'blocks.13.ln2_post.hook_scale', 'blocks.13.ln2_post.hook_normalized', 'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_post', 'blocks.14.hook_resid_pre', 'blocks.14.ln1.hook_scale', 'blocks.14.ln1.hook_normalized', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_k', 'blocks.14.attn.hook_v', 'blocks.14.attn.hook_rot_q', 'blocks.14.attn.hook_rot_k', 'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', 'blocks.14.attn.hook_z', 'blocks.14.ln1_post.hook_scale', 'blocks.14.ln1_post.hook_normalized', 'blocks.14.hook_attn_out', 'blocks.14.hook_resid_mid', 'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_pre_linear', 'blocks.14.mlp.hook_post', 'blocks.14.ln2_post.hook_scale', 'blocks.14.ln2_post.hook_normalized', 'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_post', 'blocks.15.hook_resid_pre', 'blocks.15.ln1.hook_scale', 'blocks.15.ln1.hook_normalized', 'blocks.15.attn.hook_q', 'blocks.15.attn.hook_k', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_rot_q', 'blocks.15.attn.hook_rot_k', 'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', 'blocks.15.attn.hook_z', 'blocks.15.ln1_post.hook_scale', 'blocks.15.ln1_post.hook_normalized', 'blocks.15.hook_attn_out', 'blocks.15.hook_resid_mid', 'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_pre_linear', 'blocks.15.mlp.hook_post', 'blocks.15.ln2_post.hook_scale', 'blocks.15.ln2_post.hook_normalized', 'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_post', 'blocks.16.hook_resid_pre', 'blocks.16.ln1.hook_scale', 'blocks.16.ln1.hook_normalized', 'blocks.16.attn.hook_q', 'blocks.16.attn.hook_k', 'blocks.16.attn.hook_v', 'blocks.16.attn.hook_rot_q', 'blocks.16.attn.hook_rot_k', 'blocks.16.attn.hook_attn_scores', 'blocks.16.attn.hook_pattern', 'blocks.16.attn.hook_z', 'blocks.16.ln1_post.hook_scale', 'blocks.16.ln1_post.hook_normalized', 'blocks.16.hook_attn_out', 'blocks.16.hook_resid_mid', 'blocks.16.ln2.hook_scale', 'blocks.16.ln2.hook_normalized', 'blocks.16.mlp.hook_pre', 'blocks.16.mlp.hook_pre_linear', 'blocks.16.mlp.hook_post', 'blocks.16.ln2_post.hook_scale', 'blocks.16.ln2_post.hook_normalized', 'blocks.16.hook_mlp_out', 'blocks.16.hook_resid_post', 'blocks.17.hook_resid_pre', 'blocks.17.ln1.hook_scale', 'blocks.17.ln1.hook_normalized', 'blocks.17.attn.hook_q', 'blocks.17.attn.hook_k', 'blocks.17.attn.hook_v', 'blocks.17.attn.hook_rot_q', 'blocks.17.attn.hook_rot_k', 'blocks.17.attn.hook_attn_scores', 'blocks.17.attn.hook_pattern', 'blocks.17.attn.hook_z', 'blocks.17.ln1_post.hook_scale', 'blocks.17.ln1_post.hook_normalized', 'blocks.17.hook_attn_out', 'blocks.17.hook_resid_mid', 'blocks.17.ln2.hook_scale', 'blocks.17.ln2.hook_normalized', 'blocks.17.mlp.hook_pre', 'blocks.17.mlp.hook_pre_linear', 'blocks.17.mlp.hook_post', 'blocks.17.ln2_post.hook_scale', 'blocks.17.ln2_post.hook_normalized', 'blocks.17.hook_mlp_out', 'blocks.17.hook_resid_post', 'blocks.18.hook_resid_pre', 'blocks.18.ln1.hook_scale', 'blocks.18.ln1.hook_normalized', 'blocks.18.attn.hook_q', 'blocks.18.attn.hook_k', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_rot_q', 'blocks.18.attn.hook_rot_k', 'blocks.18.attn.hook_attn_scores', 'blocks.18.attn.hook_pattern', 'blocks.18.attn.hook_z', 'blocks.18.ln1_post.hook_scale', 'blocks.18.ln1_post.hook_normalized', 'blocks.18.hook_attn_out', 'blocks.18.hook_resid_mid', 'blocks.18.ln2.hook_scale', 'blocks.18.ln2.hook_normalized', 'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_pre_linear', 'blocks.18.mlp.hook_post', 'blocks.18.ln2_post.hook_scale', 'blocks.18.ln2_post.hook_normalized', 'blocks.18.hook_mlp_out', 'blocks.18.hook_resid_post', 'blocks.19.hook_resid_pre', 'blocks.19.ln1.hook_scale', 'blocks.19.ln1.hook_normalized', 'blocks.19.attn.hook_q', 'blocks.19.attn.hook_k', 'blocks.19.attn.hook_v', 'blocks.19.attn.hook_rot_q', 'blocks.19.attn.hook_rot_k', 'blocks.19.attn.hook_attn_scores', 'blocks.19.attn.hook_pattern', 'blocks.19.attn.hook_z', 'blocks.19.ln1_post.hook_scale', 'blocks.19.ln1_post.hook_normalized', 'blocks.19.hook_attn_out', 'blocks.19.hook_resid_mid', 'blocks.19.ln2.hook_scale', 'blocks.19.ln2.hook_normalized', 'blocks.19.mlp.hook_pre', 'blocks.19.mlp.hook_pre_linear', 'blocks.19.mlp.hook_post', 'blocks.19.ln2_post.hook_scale', 'blocks.19.ln2_post.hook_normalized', 'blocks.19.hook_mlp_out', 'blocks.19.hook_resid_post', 'blocks.20.hook_resid_pre', 'blocks.20.ln1.hook_scale', 'blocks.20.ln1.hook_normalized', 'blocks.20.attn.hook_q', 'blocks.20.attn.hook_k', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_rot_q', 'blocks.20.attn.hook_rot_k', 'blocks.20.attn.hook_attn_scores', 'blocks.20.attn.hook_pattern', 'blocks.20.attn.hook_z', 'blocks.20.ln1_post.hook_scale', 'blocks.20.ln1_post.hook_normalized', 'blocks.20.hook_attn_out', 'blocks.20.hook_resid_mid', 'blocks.20.ln2.hook_scale', 'blocks.20.ln2.hook_normalized', 'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_pre_linear', 'blocks.20.mlp.hook_post', 'blocks.20.ln2_post.hook_scale', 'blocks.20.ln2_post.hook_normalized', 'blocks.20.hook_mlp_out', 'blocks.20.hook_resid_post', 'blocks.21.hook_resid_pre', 'blocks.21.ln1.hook_scale', 'blocks.21.ln1.hook_normalized', 'blocks.21.attn.hook_q', 'blocks.21.attn.hook_k', 'blocks.21.attn.hook_v', 'blocks.21.attn.hook_rot_q', 'blocks.21.attn.hook_rot_k', 'blocks.21.attn.hook_attn_scores', 'blocks.21.attn.hook_pattern', 'blocks.21.attn.hook_z', 'blocks.21.ln1_post.hook_scale', 'blocks.21.ln1_post.hook_normalized', 'blocks.21.hook_attn_out', 'blocks.21.hook_resid_mid', 'blocks.21.ln2.hook_scale', 'blocks.21.ln2.hook_normalized', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_pre_linear', 'blocks.21.mlp.hook_post', 'blocks.21.ln2_post.hook_scale', 'blocks.21.ln2_post.hook_normalized', 'blocks.21.hook_mlp_out', 'blocks.21.hook_resid_post', 'blocks.22.hook_resid_pre', 'blocks.22.ln1.hook_scale', 'blocks.22.ln1.hook_normalized', 'blocks.22.attn.hook_q', 'blocks.22.attn.hook_k', 'blocks.22.attn.hook_v', 'blocks.22.attn.hook_rot_q', 'blocks.22.attn.hook_rot_k', 'blocks.22.attn.hook_attn_scores', 'blocks.22.attn.hook_pattern', 'blocks.22.attn.hook_z', 'blocks.22.ln1_post.hook_scale', 'blocks.22.ln1_post.hook_normalized', 'blocks.22.hook_attn_out', 'blocks.22.hook_resid_mid', 'blocks.22.ln2.hook_scale', 'blocks.22.ln2.hook_normalized', 'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_pre_linear', 'blocks.22.mlp.hook_post', 'blocks.22.ln2_post.hook_scale', 'blocks.22.ln2_post.hook_normalized', 'blocks.22.hook_mlp_out', 'blocks.22.hook_resid_post', 'blocks.23.hook_resid_pre', 'blocks.23.ln1.hook_scale', 'blocks.23.ln1.hook_normalized', 'blocks.23.attn.hook_q', 'blocks.23.attn.hook_k', 'blocks.23.attn.hook_v', 'blocks.23.attn.hook_rot_q', 'blocks.23.attn.hook_rot_k', 'blocks.23.attn.hook_attn_scores', 'blocks.23.attn.hook_pattern', 'blocks.23.attn.hook_z', 'blocks.23.ln1_post.hook_scale', 'blocks.23.ln1_post.hook_normalized', 'blocks.23.hook_attn_out', 'blocks.23.hook_resid_mid', 'blocks.23.ln2.hook_scale', 'blocks.23.ln2.hook_normalized', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_pre_linear', 'blocks.23.mlp.hook_post', 'blocks.23.ln2_post.hook_scale', 'blocks.23.ln2_post.hook_normalized', 'blocks.23.hook_mlp_out', 'blocks.23.hook_resid_post', 'blocks.24.hook_resid_pre', 'blocks.24.ln1.hook_scale', 'blocks.24.ln1.hook_normalized', 'blocks.24.attn.hook_q', 'blocks.24.attn.hook_k', 'blocks.24.attn.hook_v', 'blocks.24.attn.hook_rot_q', 'blocks.24.attn.hook_rot_k', 'blocks.24.attn.hook_attn_scores', 'blocks.24.attn.hook_pattern', 'blocks.24.attn.hook_z', 'blocks.24.ln1_post.hook_scale', 'blocks.24.ln1_post.hook_normalized', 'blocks.24.hook_attn_out', 'blocks.24.hook_resid_mid', 'blocks.24.ln2.hook_scale', 'blocks.24.ln2.hook_normalized', 'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_pre_linear', 'blocks.24.mlp.hook_post', 'blocks.24.ln2_post.hook_scale', 'blocks.24.ln2_post.hook_normalized', 'blocks.24.hook_mlp_out', 'blocks.24.hook_resid_post', 'blocks.25.hook_resid_pre', 'blocks.25.ln1.hook_scale', 'blocks.25.ln1.hook_normalized', 'blocks.25.attn.hook_q', 'blocks.25.attn.hook_k', 'blocks.25.attn.hook_v', 'blocks.25.attn.hook_rot_q', 'blocks.25.attn.hook_rot_k', 'blocks.25.attn.hook_attn_scores', 'blocks.25.attn.hook_pattern', 'blocks.25.attn.hook_z', 'blocks.25.ln1_post.hook_scale', 'blocks.25.ln1_post.hook_normalized', 'blocks.25.hook_attn_out', 'blocks.25.hook_resid_mid', 'blocks.25.ln2.hook_scale', 'blocks.25.ln2.hook_normalized', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_pre_linear', 'blocks.25.mlp.hook_post', 'blocks.25.ln2_post.hook_scale', 'blocks.25.ln2_post.hook_normalized', 'blocks.25.hook_mlp_out', 'blocks.25.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 8, 256]), torch.Size([1, 5, 2304]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.attn.hook_z'].shape, cache['blocks.0.hook_attn_out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg.d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 8, 256, 2304])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W_O.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#examples = generate_dataset(N=9999, M=2, E=3)\n",
    "examples = pd.read_csv('gemma-2-2b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [16:54<00:00,  6.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils import get_completions, get_predictions\n",
    "\n",
    "completions = []\n",
    "\n",
    "bs = 128\n",
    "K = 4\n",
    "\n",
    "for b in tqdm(range(0, len(examples), bs)):\n",
    "    example = examples[\"prompt\"].iloc[b : b + bs].tolist()\n",
    "    tokens = tokenizer(example, return_tensors='pt', padding=True)['input_ids'].to('cuda')  # [bs, seq_len]\n",
    "\n",
    "    for k in range(K):\n",
    "        with torch.no_grad():\n",
    "            logits = model(tokens).logits\n",
    "\n",
    "        new_tok = logits[:, -1].argmax(-1)  # [bs]\n",
    "        tokens = torch.cat([tokens, new_tok[:, None]], -1)\n",
    "\n",
    "    completions += tokenizer.batch_decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "completions = pd.Series(completions).apply(lambda x: x.strip())\n",
    "\n",
    "predictions = get_predictions(completions)\n",
    "\n",
    "examples['completion'] = completions\n",
    "examples['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9036903690369037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples['correct'] = examples['solution'] == examples['prediction']\n",
    "examples['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples['bin'] = pd.cut(examples['solution'], bins=range(0, 10000, 50), right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26071/526257734.py:3: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Bin=%{x}<br>Accuracy=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "skyblue",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "[0, 50)",
          "[50, 100)",
          "[100, 150)",
          "[150, 200)",
          "[200, 250)",
          "[250, 300)",
          "[300, 350)",
          "[350, 400)",
          "[400, 450)",
          "[450, 500)",
          "[500, 550)",
          "[550, 600)",
          "[600, 650)",
          "[650, 700)",
          "[700, 750)",
          "[750, 800)",
          "[800, 850)",
          "[850, 900)",
          "[900, 950)",
          "[950, 1000)",
          "[1000, 1050)",
          "[1050, 1100)",
          "[1100, 1150)",
          "[1150, 1200)",
          "[1200, 1250)",
          "[1250, 1300)",
          "[1300, 1350)",
          "[1350, 1400)",
          "[1400, 1450)",
          "[1450, 1500)",
          "[1500, 1550)",
          "[1550, 1600)",
          "[1600, 1650)",
          "[1650, 1700)",
          "[1700, 1750)",
          "[1750, 1800)",
          "[1800, 1850)",
          "[1850, 1900)",
          "[1900, 1950)",
          "[1950, 2000)",
          "[2000, 2050)",
          "[2050, 2100)",
          "[2100, 2150)",
          "[2150, 2200)",
          "[2200, 2250)",
          "[2250, 2300)",
          "[2300, 2350)",
          "[2350, 2400)",
          "[2400, 2450)",
          "[2450, 2500)",
          "[2500, 2550)",
          "[2550, 2600)",
          "[2600, 2650)",
          "[2650, 2700)",
          "[2700, 2750)",
          "[2750, 2800)",
          "[2800, 2850)",
          "[2850, 2900)",
          "[2900, 2950)",
          "[2950, 3000)",
          "[3000, 3050)",
          "[3050, 3100)",
          "[3100, 3150)",
          "[3150, 3200)",
          "[3200, 3250)",
          "[3250, 3300)",
          "[3300, 3350)",
          "[3350, 3400)",
          "[3400, 3450)",
          "[3450, 3500)",
          "[3500, 3550)",
          "[3550, 3600)",
          "[3600, 3650)",
          "[3650, 3700)",
          "[3700, 3750)",
          "[3750, 3800)",
          "[3800, 3850)",
          "[3850, 3900)",
          "[3900, 3950)",
          "[3950, 4000)",
          "[4000, 4050)",
          "[4050, 4100)",
          "[4100, 4150)",
          "[4150, 4200)",
          "[4200, 4250)",
          "[4250, 4300)",
          "[4300, 4350)",
          "[4350, 4400)",
          "[4400, 4450)",
          "[4450, 4500)",
          "[4500, 4550)",
          "[4550, 4600)",
          "[4600, 4650)",
          "[4650, 4700)",
          "[4700, 4750)",
          "[4750, 4800)",
          "[4800, 4850)",
          "[4850, 4900)",
          "[4900, 4950)",
          "[4950, 5000)",
          "[5000, 5050)",
          "[5050, 5100)",
          "[5100, 5150)",
          "[5150, 5200)",
          "[5200, 5250)",
          "[5250, 5300)",
          "[5300, 5350)",
          "[5350, 5400)",
          "[5400, 5450)",
          "[5450, 5500)",
          "[5500, 5550)",
          "[5550, 5600)",
          "[5600, 5650)",
          "[5650, 5700)",
          "[5700, 5750)",
          "[5750, 5800)",
          "[5800, 5850)",
          "[5850, 5900)",
          "[5900, 5950)",
          "[5950, 6000)",
          "[6000, 6050)",
          "[6050, 6100)",
          "[6100, 6150)",
          "[6150, 6200)",
          "[6200, 6250)",
          "[6250, 6300)",
          "[6300, 6350)",
          "[6350, 6400)",
          "[6400, 6450)",
          "[6450, 6500)",
          "[6500, 6550)",
          "[6550, 6600)",
          "[6600, 6650)",
          "[6650, 6700)",
          "[6700, 6750)",
          "[6750, 6800)",
          "[6800, 6850)",
          "[6850, 6900)",
          "[6900, 6950)",
          "[6950, 7000)",
          "[7000, 7050)",
          "[7050, 7100)",
          "[7100, 7150)",
          "[7150, 7200)",
          "[7200, 7250)",
          "[7250, 7300)",
          "[7300, 7350)",
          "[7350, 7400)",
          "[7400, 7450)",
          "[7450, 7500)",
          "[7500, 7550)",
          "[7550, 7600)",
          "[7600, 7650)",
          "[7650, 7700)",
          "[7700, 7750)",
          "[7750, 7800)",
          "[7800, 7850)",
          "[7850, 7900)",
          "[7900, 7950)",
          "[7950, 8000)",
          "[8000, 8050)",
          "[8050, 8100)",
          "[8100, 8150)",
          "[8150, 8200)",
          "[8200, 8250)",
          "[8250, 8300)",
          "[8300, 8350)",
          "[8350, 8400)",
          "[8400, 8450)",
          "[8450, 8500)",
          "[8500, 8550)",
          "[8550, 8600)",
          "[8600, 8650)",
          "[8650, 8700)",
          "[8700, 8750)",
          "[8750, 8800)",
          "[8800, 8850)",
          "[8850, 8900)",
          "[8900, 8950)",
          "[8950, 9000)",
          "[9000, 9050)",
          "[9050, 9100)",
          "[9100, 9150)",
          "[9150, 9200)",
          "[9200, 9250)",
          "[9250, 9300)",
          "[9300, 9350)",
          "[9350, 9400)",
          "[9400, 9450)",
          "[9450, 9500)",
          "[9500, 9550)",
          "[9550, 9600)",
          "[9600, 9650)",
          "[9650, 9700)",
          "[9700, 9750)",
          "[9750, 9800)",
          "[9800, 9850)",
          "[9850, 9900)",
          "[9900, 9950)"
         ],
         "xaxis": "x",
         "y": [
          0.97,
          0.95,
          0.99,
          0.97,
          0.94,
          0.96,
          0.89,
          0.97,
          0.85,
          0.91,
          0.92,
          0.94,
          0.92,
          0.94,
          0.92,
          0.94,
          0.97,
          0.95,
          0.94,
          0.94,
          0.86,
          0.95,
          0.95,
          0.96,
          0.98,
          0.94,
          0.9,
          0.92,
          0.94,
          0.96,
          0.95,
          0.9,
          0.92,
          0.93,
          0.92,
          0.89,
          0.93,
          0.92,
          0.96,
          0.96,
          0.83,
          0.88,
          0.95,
          0.96,
          0.95,
          0.93,
          0.91,
          0.97,
          0.96,
          0.97,
          0.95,
          0.95,
          0.89,
          0.91,
          0.93,
          0.92,
          0.91,
          0.96,
          0.76,
          0.68,
          0.74,
          0.9,
          0.93,
          0.92,
          0.92,
          0.91,
          0.93,
          0.92,
          0.94,
          0.87,
          0.93,
          0.91,
          0.9,
          0.88,
          0.9,
          0.91,
          0.94,
          0.95,
          0.86,
          0.67,
          0.7,
          0.85,
          0.93,
          0.91,
          0.97,
          0.88,
          0.9,
          0.92,
          0.89,
          0.92,
          0.97,
          0.93,
          0.89,
          0.93,
          0.92,
          0.93,
          0.95,
          0.92,
          0.89,
          0.69,
          0.69,
          0.86,
          0.96,
          0.92,
          0.94,
          0.96,
          0.9,
          0.97,
          0.87,
          0.88,
          0.93,
          0.9,
          0.94,
          0.91,
          0.88,
          0.93,
          0.94,
          0.91,
          0.82,
          0.74,
          0.66,
          0.79,
          0.92,
          0.89,
          0.89,
          0.96,
          0.97,
          0.91,
          0.95,
          0.95,
          0.92,
          0.97,
          0.92,
          0.9,
          0.92,
          0.95,
          0.89,
          0.91,
          0.82,
          0.65,
          0.66,
          0.85,
          0.94,
          0.91,
          0.99,
          0.93,
          0.9,
          0.93,
          0.96,
          0.96,
          0.96,
          0.98,
          0.92,
          0.89,
          0.88,
          0.9,
          0.91,
          0.88,
          0.86,
          0.66,
          0.64,
          0.85,
          0.93,
          0.94,
          0.94,
          0.9,
          0.93,
          0.97,
          0.96,
          0.9,
          0.94,
          0.98,
          0.95,
          0.92,
          0.96,
          0.92,
          0.9,
          0.89,
          0.84,
          0.7,
          0.63,
          0.81,
          0.9,
          0.93,
          0.96,
          0.88,
          0.95,
          0.95,
          0.95,
          0.92,
          0.96,
          0.94,
          0.92,
          0.94,
          0.94,
          0.89,
          0.9,
          0.93,
          0.87
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gemma-2-2b accuracy by bin"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": 90,
         "title": {
          "text": "Bin"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"02ad23bc-2026-4031-86cf-f1f4d2c0e151\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"02ad23bc-2026-4031-86cf-f1f4d2c0e151\")) {                    Plotly.newPlot(                        \"02ad23bc-2026-4031-86cf-f1f4d2c0e151\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Bin=%{x}\\u003cbr\\u003eAccuracy=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"skyblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"[0, 50)\",\"[50, 100)\",\"[100, 150)\",\"[150, 200)\",\"[200, 250)\",\"[250, 300)\",\"[300, 350)\",\"[350, 400)\",\"[400, 450)\",\"[450, 500)\",\"[500, 550)\",\"[550, 600)\",\"[600, 650)\",\"[650, 700)\",\"[700, 750)\",\"[750, 800)\",\"[800, 850)\",\"[850, 900)\",\"[900, 950)\",\"[950, 1000)\",\"[1000, 1050)\",\"[1050, 1100)\",\"[1100, 1150)\",\"[1150, 1200)\",\"[1200, 1250)\",\"[1250, 1300)\",\"[1300, 1350)\",\"[1350, 1400)\",\"[1400, 1450)\",\"[1450, 1500)\",\"[1500, 1550)\",\"[1550, 1600)\",\"[1600, 1650)\",\"[1650, 1700)\",\"[1700, 1750)\",\"[1750, 1800)\",\"[1800, 1850)\",\"[1850, 1900)\",\"[1900, 1950)\",\"[1950, 2000)\",\"[2000, 2050)\",\"[2050, 2100)\",\"[2100, 2150)\",\"[2150, 2200)\",\"[2200, 2250)\",\"[2250, 2300)\",\"[2300, 2350)\",\"[2350, 2400)\",\"[2400, 2450)\",\"[2450, 2500)\",\"[2500, 2550)\",\"[2550, 2600)\",\"[2600, 2650)\",\"[2650, 2700)\",\"[2700, 2750)\",\"[2750, 2800)\",\"[2800, 2850)\",\"[2850, 2900)\",\"[2900, 2950)\",\"[2950, 3000)\",\"[3000, 3050)\",\"[3050, 3100)\",\"[3100, 3150)\",\"[3150, 3200)\",\"[3200, 3250)\",\"[3250, 3300)\",\"[3300, 3350)\",\"[3350, 3400)\",\"[3400, 3450)\",\"[3450, 3500)\",\"[3500, 3550)\",\"[3550, 3600)\",\"[3600, 3650)\",\"[3650, 3700)\",\"[3700, 3750)\",\"[3750, 3800)\",\"[3800, 3850)\",\"[3850, 3900)\",\"[3900, 3950)\",\"[3950, 4000)\",\"[4000, 4050)\",\"[4050, 4100)\",\"[4100, 4150)\",\"[4150, 4200)\",\"[4200, 4250)\",\"[4250, 4300)\",\"[4300, 4350)\",\"[4350, 4400)\",\"[4400, 4450)\",\"[4450, 4500)\",\"[4500, 4550)\",\"[4550, 4600)\",\"[4600, 4650)\",\"[4650, 4700)\",\"[4700, 4750)\",\"[4750, 4800)\",\"[4800, 4850)\",\"[4850, 4900)\",\"[4900, 4950)\",\"[4950, 5000)\",\"[5000, 5050)\",\"[5050, 5100)\",\"[5100, 5150)\",\"[5150, 5200)\",\"[5200, 5250)\",\"[5250, 5300)\",\"[5300, 5350)\",\"[5350, 5400)\",\"[5400, 5450)\",\"[5450, 5500)\",\"[5500, 5550)\",\"[5550, 5600)\",\"[5600, 5650)\",\"[5650, 5700)\",\"[5700, 5750)\",\"[5750, 5800)\",\"[5800, 5850)\",\"[5850, 5900)\",\"[5900, 5950)\",\"[5950, 6000)\",\"[6000, 6050)\",\"[6050, 6100)\",\"[6100, 6150)\",\"[6150, 6200)\",\"[6200, 6250)\",\"[6250, 6300)\",\"[6300, 6350)\",\"[6350, 6400)\",\"[6400, 6450)\",\"[6450, 6500)\",\"[6500, 6550)\",\"[6550, 6600)\",\"[6600, 6650)\",\"[6650, 6700)\",\"[6700, 6750)\",\"[6750, 6800)\",\"[6800, 6850)\",\"[6850, 6900)\",\"[6900, 6950)\",\"[6950, 7000)\",\"[7000, 7050)\",\"[7050, 7100)\",\"[7100, 7150)\",\"[7150, 7200)\",\"[7200, 7250)\",\"[7250, 7300)\",\"[7300, 7350)\",\"[7350, 7400)\",\"[7400, 7450)\",\"[7450, 7500)\",\"[7500, 7550)\",\"[7550, 7600)\",\"[7600, 7650)\",\"[7650, 7700)\",\"[7700, 7750)\",\"[7750, 7800)\",\"[7800, 7850)\",\"[7850, 7900)\",\"[7900, 7950)\",\"[7950, 8000)\",\"[8000, 8050)\",\"[8050, 8100)\",\"[8100, 8150)\",\"[8150, 8200)\",\"[8200, 8250)\",\"[8250, 8300)\",\"[8300, 8350)\",\"[8350, 8400)\",\"[8400, 8450)\",\"[8450, 8500)\",\"[8500, 8550)\",\"[8550, 8600)\",\"[8600, 8650)\",\"[8650, 8700)\",\"[8700, 8750)\",\"[8750, 8800)\",\"[8800, 8850)\",\"[8850, 8900)\",\"[8900, 8950)\",\"[8950, 9000)\",\"[9000, 9050)\",\"[9050, 9100)\",\"[9100, 9150)\",\"[9150, 9200)\",\"[9200, 9250)\",\"[9250, 9300)\",\"[9300, 9350)\",\"[9350, 9400)\",\"[9400, 9450)\",\"[9450, 9500)\",\"[9500, 9550)\",\"[9550, 9600)\",\"[9600, 9650)\",\"[9650, 9700)\",\"[9700, 9750)\",\"[9750, 9800)\",\"[9800, 9850)\",\"[9850, 9900)\",\"[9900, 9950)\"],\"xaxis\":\"x\",\"y\":[0.97,0.95,0.99,0.97,0.94,0.96,0.89,0.97,0.85,0.91,0.92,0.94,0.92,0.94,0.92,0.94,0.97,0.95,0.94,0.94,0.86,0.95,0.95,0.96,0.98,0.94,0.9,0.92,0.94,0.96,0.95,0.9,0.92,0.93,0.92,0.89,0.93,0.92,0.96,0.96,0.83,0.88,0.95,0.96,0.95,0.93,0.91,0.97,0.96,0.97,0.95,0.95,0.89,0.91,0.93,0.92,0.91,0.96,0.76,0.68,0.74,0.9,0.93,0.92,0.92,0.91,0.93,0.92,0.94,0.87,0.93,0.91,0.9,0.88,0.9,0.91,0.94,0.95,0.86,0.67,0.7,0.85,0.93,0.91,0.97,0.88,0.9,0.92,0.89,0.92,0.97,0.93,0.89,0.93,0.92,0.93,0.95,0.92,0.89,0.69,0.69,0.86,0.96,0.92,0.94,0.96,0.9,0.97,0.87,0.88,0.93,0.9,0.94,0.91,0.88,0.93,0.94,0.91,0.82,0.74,0.66,0.79,0.92,0.89,0.89,0.96,0.97,0.91,0.95,0.95,0.92,0.97,0.92,0.9,0.92,0.95,0.89,0.91,0.82,0.65,0.66,0.85,0.94,0.91,0.99,0.93,0.9,0.93,0.96,0.96,0.96,0.98,0.92,0.89,0.88,0.9,0.91,0.88,0.86,0.66,0.64,0.85,0.93,0.94,0.94,0.9,0.93,0.97,0.96,0.9,0.94,0.98,0.95,0.92,0.96,0.92,0.9,0.89,0.84,0.7,0.63,0.81,0.9,0.93,0.96,0.88,0.95,0.95,0.95,0.92,0.96,0.94,0.92,0.94,0.94,0.89,0.9,0.93,0.87],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Bin\"},\"tickangle\":90},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Accuracy\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Gemma-2-2b accuracy by bin\"},\"barmode\":\"relative\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('02ad23bc-2026-4031-86cf-f1f4d2c0e151');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df_grouped = examples.groupby('bin')['correct'].mean().reset_index()\n",
    "df_grouped['bin'] = df_grouped['bin'].astype(str)\n",
    "\n",
    "fig = px.bar(\n",
    "    df_grouped,\n",
    "    x='bin',\n",
    "    y='correct',\n",
    "    title=\"Gemma-2-2b accuracy by bin\",\n",
    "    labels={'correct': 'Accuracy', 'bin': 'Bin'},\n",
    "    color_discrete_sequence=['skyblue']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    xaxis_title=\"Bin\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "fig.update_xaxes(tickangle=90)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examples.to_csv('gemma-2-2b.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_dataset(N, min_n, max_n, E=0):\n",
    "\n",
    "    zeros = 4\n",
    "\n",
    "    def add_zeros(x, L):\n",
    "        return \"0\" * max(0, zeros - len(str(x))) + str(x)\n",
    "\n",
    "    examples = {\n",
    "        \"x_clean\": [],\n",
    "        \"x_corr\": [],\n",
    "        \"a\": [],\n",
    "        \"b\": [],\n",
    "        \"b_corr\": [],\n",
    "        \"s\": [],\n",
    "        \"s_corr\": []\n",
    "    }\n",
    "\n",
    "    for n in range(0, N):\n",
    "        prompt = \"\"\n",
    "\n",
    "        for _ in range(E):\n",
    "            a, b = np.random.randint(min_n, max_n+1, 2)\n",
    "            c = add_zeros(a + b, zeros)\n",
    "            a, b = add_zeros(a, zeros), add_zeros(b, zeros)\n",
    "            prompt += f\"{a}+{b}={c}\\n\"\n",
    "\n",
    "        a, b = np.random.randint(min_n, max_n+1, 2)\n",
    "        c = add_zeros(a + b, zeros)\n",
    "        a, b = add_zeros(a, zeros), add_zeros(b, zeros)\n",
    "        \n",
    "        change_digit = np.random.randint(1, len(str(max_n)))\n",
    "        b_corr = list(b)\n",
    "        b_corr[-change_digit] = str(np.random.randint(0, 10))\n",
    "        b_corr = \"\".join(b_corr)\n",
    "        c_corr = add_zeros(int(a) + int(b_corr), zeros)\n",
    "\n",
    "        idx = 0\n",
    "        for i in range(len(c)):\n",
    "            if c[i] != c_corr[i]:\n",
    "                idx = i\n",
    "                break\n",
    "\n",
    "        prompt_corr = prompt + f\"{a}+{b_corr}=\" + c_corr[:idx]\n",
    "        prompt += f\"{a}+{b}=\" + c[:idx]\n",
    "        \n",
    "        examples[\"x_clean\"].append(prompt)\n",
    "        examples[\"x_corr\"].append(prompt_corr)\n",
    "\n",
    "        examples[\"a\"].append(a)\n",
    "        examples[\"b\"].append(b)\n",
    "        examples[\"b_corr\"].append(b_corr)\n",
    "\n",
    "        examples[\"s\"].append(c)\n",
    "        examples[\"s_corr\"].append(c_corr)\n",
    "\n",
    "    examples = pd.DataFrame(examples)\n",
    "\n",
    "    def BA(x):\n",
    "        BAs = [(int(x[\"a\"][i]) + int(x[\"b\"][i])) % 10 for i in range(zeros)]\n",
    "        return BAs\n",
    "\n",
    "    def MC(x):\n",
    "        MCs = [(int(x[\"a\"][i]) + int(x[\"b\"][i])) > 9 for i in range(zeros)]\n",
    "        return MCs\n",
    "\n",
    "    def MS9(x):\n",
    "        MS9s = [(int(x[\"a\"][i]) + int(x[\"b\"][i])) == 9 for i in range(zeros)]\n",
    "        return MS9s\n",
    "\n",
    "    examples[[\"BAth\", \"BAhu\", \"BAte\", \"BAun\"]] = examples.apply(lambda x: BA(x), axis=1, result_type=\"expand\")\n",
    "    examples[[\"MCth\", \"MChu\", \"MCte\", \"MCun\"]] = examples.apply(lambda x: MC(x), axis=1, result_type=\"expand\")\n",
    "    examples[[\"MS9th\", \"MS9hu\", \"MS9te\", \"MS9un\"]] = examples.apply(lambda x: MS9(x), axis=1, result_type=\"expand\")\n",
    "\n",
    "    def US9(x):\n",
    "        US9s = [False]\n",
    "\n",
    "        for i, j in zip([\"te\", \"hu\", \"th\"], [\"un\", \"te\", \"hu\"]):\n",
    "            US9s.append(x[f\"MS9{i}\"] and (x[f\"MC{j}\"] or US9s[-1]))\n",
    "        \n",
    "        return US9s\n",
    "\n",
    "    examples[[\"US9un\", \"US9te\", \"US9hu\", \"US9th\"]] = examples.apply(lambda x: US9(x), axis=1, result_type=\"expand\")\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_dataset(1024, 500, 1500, E=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCth     0.000000\n",
       "MChu     0.458984\n",
       "MCte     0.447266\n",
       "MCun     0.457031\n",
       "MS9th    0.000000\n",
       "MS9hu    0.116211\n",
       "MS9te    0.118164\n",
       "MS9un    0.115234\n",
       "US9un    0.000000\n",
       "US9te    0.044922\n",
       "US9hu    0.049805\n",
       "US9th    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, 11:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "lm = LanguageModel(model, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_learning. import AutoEncoder\n",
    "\n",
    "ae = AutoEncoder.from_pretrained_npz('dictionary_learning/attn_out_layer_0/params.npz', activation_dim=2304, dict_size=16384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304, 16384)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['W_enc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 17534,  2134,   749]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('hello world do', return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2, 1721]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(' does', return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
